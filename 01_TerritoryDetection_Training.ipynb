{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dee4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d856956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos\"\n",
      "Created \"/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/labeled-data\"\n",
      "Created \"/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/training-datasets\"\n",
      "Created \"/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/dlc-models\"\n",
      "Copying the videos\n",
      "/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos/20230303_SE_Lek1_P1D2_DJI_0691.MP4\n",
      "/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos/20230303_SM_Lek1_P1D1_DJI_0904.MP4\n",
      "/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos/20230312_SE_Lek1_P1D2_DJI_0002.MP4\n",
      "/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos/20230312_SM_Lek1_P1D1_DJI_0250.MP4\n",
      "/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos/20230316_SE_Lek1_P1D2_DJI_0097.MP4\n",
      "/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/videos/20230318_SM_Lek1_P1D1_DJI_0415.MP4\n",
      "Generated \"/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/config.yaml\"\n",
      "\n",
      "A new project with name 06_TerritoryDetectionP1-Vivek-2023-08-01 is created at /media/vsridhar/DATA/DeepLabCut/projects and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "project_name = '06_TerritoryDetectionP1'\n",
    "experimenter = 'Vivek'\n",
    "video_path = ['/media/vsridhar/T7/Work/Data/BlackbuckAnnotations/P1/downsampled/annotations/20230303_SE_Lek1_P1D2_DJI_0691.MP4', \n",
    "             '/media/vsridhar/T7/Work/Data/BlackbuckAnnotations/P1/downsampled/annotations/20230303_SM_Lek1_P1D1_DJI_0904.MP4', \n",
    "             '/media/vsridhar/T7/Work/Data/BlackbuckAnnotations/P1/downsampled/annotations/20230312_SE_Lek1_P1D2_DJI_0002.MP4', \n",
    "             '/media/vsridhar/T7/Work/Data/BlackbuckAnnotations/P1/downsampled/annotations/20230312_SM_Lek1_P1D1_DJI_0250.MP4', \n",
    "             '/media/vsridhar/T7/Work/Data/BlackbuckAnnotations/P1/downsampled/annotations/20230316_SE_Lek1_P1D2_DJI_0097.MP4', \n",
    "             '/media/vsridhar/T7/Work/Data/BlackbuckAnnotations/P1/downsampled/annotations/20230318_SM_Lek1_P1D1_DJI_0415.MP4']\n",
    "work_dir = '/home/vsridhar/DATA/DeepLabCut/projects/'\n",
    "config_path = deeplabcut.create_new_project(project_name, \n",
    "                                            experimenter, \n",
    "                                            video_path, \n",
    "                                            working_directory=work_dir, \n",
    "                                            copy_videos=True, \n",
    "                                            multianimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f270e743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 193.59  seconds.\n",
      "Extracting and downsampling... 5802  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5802it [01:01, 94.60it/s] \n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 193.66  seconds.\n",
      "Extracting and downsampling... 5804  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5804it [01:01, 94.65it/s] \n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 193.66  seconds.\n",
      "Extracting and downsampling... 5804  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5804it [01:01, 95.00it/s] \n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 193.56  seconds.\n",
      "Extracting and downsampling... 5801  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5801it [01:01, 94.82it/s] \n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 193.66  seconds.\n",
      "Extracting and downsampling... 5804  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5804it [01:00, 96.63it/s] \n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 193.56  seconds.\n",
      "Extracting and downsampling... 5801  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5801it [00:59, 96.97it/s] \n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, \n",
    "                          mode='automatic', \n",
    "                          algo='kmeans', \n",
    "                          userfeedback=False, \n",
    "                          crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0d9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53dbe342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Vivek.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path, \n",
    "                        draw_skeleton=False, \n",
    "                        visualizeindividuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c48243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing the following graph: [[0, 1], [0, 2], [1, 2]]\n",
      "Creating training data for: Shuffle: 1 TrainFraction:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 1144.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_multianimaltraining_dataset(config_path,\n",
    "                                              num_shuffles=1,\n",
    "                                              net_type='dlcrnet_ms5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3084ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['centre', 'left', 'right'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 8,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'crop_sampling': 'hybrid',\n",
      " 'crop_size': [400, 400],\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_06_TerritoryDetectionP1Aug1/06_TerritoryDetectionP1_Vivek90shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/vsridhar/.local/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'max_shift': 0.4,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_06_TerritoryDetectionP1Aug1/Documentation_data-06_TerritoryDetectionP1_90shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': True,\n",
      " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_idchannel': 0,\n",
      " 'num_joints': 3,\n",
      " 'num_limbs': 3,\n",
      " 'optimizer': 'adam',\n",
      " 'pafwidth': 20,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_loss_weight': 0.1,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'pre_resize': [],\n",
      " 'project_path': '/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 10000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/dlc-models/iteration-0/06_TerritoryDetectionP1Aug1-trainset90shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting multi-animal trainer\n",
      "Activating limb prediction...\n",
      "Batch Size is 8\n",
      "Getting specs multi-animal-imgaug 3 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsridhar/.local/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n",
      "2023-08-01 16:58:30.570247: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n",
      "Max_iters overwritten as 50000\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 10000\n",
      "Training parameters:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/dlc-models/iteration-0/06_TerritoryDetectionP1Aug1-trainset90shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'adam', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 8, 'dataset_type': 'multi-animal-imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': True, 'pairwise_predict': True, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['centre', 'left', 'right'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'crop_sampling': 'hybrid', 'crop_size': [400, 400], 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_06_TerritoryDetectionP1Aug1/06_TerritoryDetectionP1_Vivek90shuffle1.pickle', 'decay_steps': 30000, 'display_iters': 500, 'init_weights': '/home/vsridhar/.local/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'max_shift': 0.4, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_06_TerritoryDetectionP1Aug1/Documentation_data-06_TerritoryDetectionP1_90shuffle1.pickle', 'min_input_size': 64, 'multi_stage': True, 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]], 'net_type': 'resnet_50', 'num_idchannel': 0, 'num_joints': 3, 'num_limbs': 3, 'pafwidth': 20, 'pairwise_loss_weight': 0.1, 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]], 'pos_dist_thresh': 17, 'pre_resize': [], 'project_path': '/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 10000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'pseudo_threshold': 0.1, 'video_path': '', 'traintime_resize': False}\n",
      "Starting multi-animal training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0693 scmap loss: 0.0564 locref loss: 0.0030 limb loss: 0.0099 lr: 0.0001\n",
      "iteration: 200 loss: 0.0218 scmap loss: 0.0194 locref loss: 0.0007 limb loss: 0.0017 lr: 0.0001\n",
      "iteration: 300 loss: 0.0186 scmap loss: 0.0169 locref loss: 0.0005 limb loss: 0.0012 lr: 0.0001\n",
      "iteration: 400 loss: 0.0163 scmap loss: 0.0150 locref loss: 0.0004 limb loss: 0.0009 lr: 0.0001\n",
      "iteration: 500 loss: 0.0171 scmap loss: 0.0160 locref loss: 0.0004 limb loss: 0.0008 lr: 0.0001\n",
      "iteration: 600 loss: 0.0153 scmap loss: 0.0143 locref loss: 0.0003 limb loss: 0.0007 lr: 0.0001\n",
      "iteration: 700 loss: 0.0166 scmap loss: 0.0155 locref loss: 0.0003 limb loss: 0.0007 lr: 0.0001\n",
      "iteration: 800 loss: 0.0148 scmap loss: 0.0139 locref loss: 0.0003 limb loss: 0.0006 lr: 0.0001\n",
      "iteration: 900 loss: 0.0144 scmap loss: 0.0135 locref loss: 0.0003 limb loss: 0.0006 lr: 0.0001\n",
      "iteration: 1000 loss: 0.0139 scmap loss: 0.0131 locref loss: 0.0002 limb loss: 0.0005 lr: 0.0001\n",
      "iteration: 1100 loss: 0.0140 scmap loss: 0.0132 locref loss: 0.0003 limb loss: 0.0005 lr: 0.0001\n",
      "iteration: 1200 loss: 0.0135 scmap loss: 0.0127 locref loss: 0.0002 limb loss: 0.0005 lr: 0.0001\n",
      "iteration: 1300 loss: 0.0133 scmap loss: 0.0125 locref loss: 0.0002 limb loss: 0.0005 lr: 0.0001\n",
      "iteration: 1400 loss: 0.0128 scmap loss: 0.0122 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 1500 loss: 0.0127 scmap loss: 0.0120 locref loss: 0.0002 limb loss: 0.0005 lr: 0.0001\n",
      "iteration: 1600 loss: 0.0128 scmap loss: 0.0121 locref loss: 0.0002 limb loss: 0.0005 lr: 0.0001\n",
      "iteration: 1700 loss: 0.0118 scmap loss: 0.0111 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 1800 loss: 0.0119 scmap loss: 0.0113 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 1900 loss: 0.0115 scmap loss: 0.0109 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 2000 loss: 0.0118 scmap loss: 0.0112 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 2100 loss: 0.0110 scmap loss: 0.0104 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 2200 loss: 0.0106 scmap loss: 0.0100 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 2300 loss: 0.0112 scmap loss: 0.0107 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 2400 loss: 0.0110 scmap loss: 0.0105 locref loss: 0.0002 limb loss: 0.0004 lr: 0.0001\n",
      "iteration: 2500 loss: 0.0104 scmap loss: 0.0099 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 2600 loss: 0.0108 scmap loss: 0.0103 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 2700 loss: 0.0106 scmap loss: 0.0102 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 2800 loss: 0.0096 scmap loss: 0.0092 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 2900 loss: 0.0102 scmap loss: 0.0097 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3000 loss: 0.0099 scmap loss: 0.0095 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3100 loss: 0.0109 scmap loss: 0.0105 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3200 loss: 0.0105 scmap loss: 0.0100 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3300 loss: 0.0110 scmap loss: 0.0105 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3400 loss: 0.0106 scmap loss: 0.0102 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3500 loss: 0.0103 scmap loss: 0.0099 locref loss: 0.0001 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3600 loss: 0.0106 scmap loss: 0.0101 locref loss: 0.0002 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3700 loss: 0.0095 scmap loss: 0.0091 locref loss: 0.0001 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3800 loss: 0.0092 scmap loss: 0.0088 locref loss: 0.0001 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 3900 loss: 0.0102 scmap loss: 0.0098 locref loss: 0.0001 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 4000 loss: 0.0099 scmap loss: 0.0095 locref loss: 0.0001 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 4100 loss: 0.0100 scmap loss: 0.0096 locref loss: 0.0001 limb loss: 0.0003 lr: 0.0001\n",
      "iteration: 4200 loss: 0.0104 scmap loss: 0.0100 locref loss: 0.0002 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4300 loss: 0.0091 scmap loss: 0.0088 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4400 loss: 0.0094 scmap loss: 0.0091 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4500 loss: 0.0093 scmap loss: 0.0089 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4600 loss: 0.0098 scmap loss: 0.0094 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4700 loss: 0.0080 scmap loss: 0.0077 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4800 loss: 0.0102 scmap loss: 0.0098 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 4900 loss: 0.0088 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5000 loss: 0.0089 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5100 loss: 0.0088 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5200 loss: 0.0091 scmap loss: 0.0088 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5300 loss: 0.0087 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5400 loss: 0.0087 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5500 loss: 0.0088 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5600 loss: 0.0089 scmap loss: 0.0086 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5700 loss: 0.0095 scmap loss: 0.0091 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5800 loss: 0.0090 scmap loss: 0.0087 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 5900 loss: 0.0089 scmap loss: 0.0086 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6000 loss: 0.0088 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6100 loss: 0.0089 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6200 loss: 0.0093 scmap loss: 0.0090 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6300 loss: 0.0092 scmap loss: 0.0089 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6400 loss: 0.0087 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6500 loss: 0.0086 scmap loss: 0.0083 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6600 loss: 0.0088 scmap loss: 0.0085 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6700 loss: 0.0087 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6800 loss: 0.0082 scmap loss: 0.0079 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 6900 loss: 0.0080 scmap loss: 0.0077 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7000 loss: 0.0084 scmap loss: 0.0082 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7100 loss: 0.0087 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7200 loss: 0.0087 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7300 loss: 0.0087 scmap loss: 0.0084 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7400 loss: 0.0080 scmap loss: 0.0077 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7500 loss: 0.0084 scmap loss: 0.0081 locref loss: 0.0001 limb loss: 0.0002 lr: 0.0001\n",
      "iteration: 7600 loss: 0.0075 scmap loss: 0.0072 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 7700 loss: 0.0074 scmap loss: 0.0072 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 7800 loss: 0.0077 scmap loss: 0.0074 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 7900 loss: 0.0075 scmap loss: 0.0073 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8000 loss: 0.0069 scmap loss: 0.0067 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8100 loss: 0.0075 scmap loss: 0.0072 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8200 loss: 0.0068 scmap loss: 0.0065 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8300 loss: 0.0079 scmap loss: 0.0077 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8400 loss: 0.0072 scmap loss: 0.0070 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8500 loss: 0.0078 scmap loss: 0.0076 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 8600 loss: 0.0068 scmap loss: 0.0066 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8700 loss: 0.0076 scmap loss: 0.0073 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8800 loss: 0.0070 scmap loss: 0.0067 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 8900 loss: 0.0073 scmap loss: 0.0070 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9000 loss: 0.0073 scmap loss: 0.0071 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9100 loss: 0.0073 scmap loss: 0.0070 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9200 loss: 0.0074 scmap loss: 0.0072 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9300 loss: 0.0076 scmap loss: 0.0074 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9400 loss: 0.0073 scmap loss: 0.0070 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9500 loss: 0.0072 scmap loss: 0.0069 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9600 loss: 0.0075 scmap loss: 0.0073 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9700 loss: 0.0067 scmap loss: 0.0065 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9800 loss: 0.0069 scmap loss: 0.0067 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 9900 loss: 0.0069 scmap loss: 0.0066 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10000 loss: 0.0070 scmap loss: 0.0068 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10100 loss: 0.0077 scmap loss: 0.0075 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10200 loss: 0.0066 scmap loss: 0.0064 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10300 loss: 0.0070 scmap loss: 0.0068 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10400 loss: 0.0071 scmap loss: 0.0068 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10500 loss: 0.0074 scmap loss: 0.0072 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10600 loss: 0.0068 scmap loss: 0.0065 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10700 loss: 0.0063 scmap loss: 0.0061 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10800 loss: 0.0069 scmap loss: 0.0067 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 10900 loss: 0.0069 scmap loss: 0.0067 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11000 loss: 0.0072 scmap loss: 0.0070 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11100 loss: 0.0064 scmap loss: 0.0062 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11200 loss: 0.0074 scmap loss: 0.0072 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11300 loss: 0.0068 scmap loss: 0.0066 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11400 loss: 0.0070 scmap loss: 0.0068 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11500 loss: 0.0063 scmap loss: 0.0061 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11600 loss: 0.0065 scmap loss: 0.0063 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11700 loss: 0.0069 scmap loss: 0.0067 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11800 loss: 0.0070 scmap loss: 0.0068 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 11900 loss: 0.0070 scmap loss: 0.0068 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 12000 loss: 0.0064 scmap loss: 0.0062 locref loss: 0.0001 limb loss: 0.0001 lr: 5e-05\n",
      "iteration: 12100 loss: 0.0065 scmap loss: 0.0064 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12200 loss: 0.0064 scmap loss: 0.0063 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12300 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12400 loss: 0.0064 scmap loss: 0.0062 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12500 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12600 loss: 0.0065 scmap loss: 0.0063 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12700 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12800 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 12900 loss: 0.0063 scmap loss: 0.0061 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13000 loss: 0.0061 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13100 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13200 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13300 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13400 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13500 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13600 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13700 loss: 0.0059 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13800 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 13900 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14000 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14100 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14200 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14300 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14400 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14500 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14600 loss: 0.0059 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14700 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14800 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 14900 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15000 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15100 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15200 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15300 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15400 loss: 0.0064 scmap loss: 0.0062 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15500 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15600 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15700 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15800 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 15900 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16000 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16100 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16200 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16300 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16400 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16500 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16600 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16700 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16800 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 16900 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17000 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 17100 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17200 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17300 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17400 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17500 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17600 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17700 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17800 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 17900 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18000 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18100 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18200 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18300 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18400 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18500 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18600 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18700 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18800 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 18900 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19000 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19100 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19200 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19300 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19400 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19500 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19600 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19700 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19800 loss: 0.0062 scmap loss: 0.0060 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 19900 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20000 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20100 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20200 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20300 loss: 0.0061 scmap loss: 0.0059 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20400 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20500 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20600 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20700 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20800 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 20900 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21000 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21100 loss: 0.0059 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21200 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21300 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21400 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21500 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21600 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21700 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21800 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 21900 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22000 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22100 loss: 0.0059 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22200 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22300 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22400 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22500 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22600 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22700 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22800 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 22900 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23000 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23100 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23200 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23300 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23400 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23500 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23600 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23700 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23800 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 23900 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24000 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24100 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24200 loss: 0.0059 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24300 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24400 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24500 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24600 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24700 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24800 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 24900 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25000 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25100 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25200 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25300 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25400 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25500 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 25600 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25700 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25800 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 25900 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26000 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26100 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26200 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26300 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26400 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26500 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26600 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26700 loss: 0.0059 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26800 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 26900 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27000 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27100 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27200 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27300 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27400 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27500 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27600 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27700 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27800 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 27900 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28000 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28100 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28200 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28300 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28400 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28500 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28600 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28700 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28800 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 28900 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29000 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29100 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29200 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29300 loss: 0.0058 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29400 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29500 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29600 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29700 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29800 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 29900 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30000 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30100 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30200 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30300 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30400 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30500 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30600 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30700 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30800 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 30900 loss: 0.0059 scmap loss: 0.0057 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31000 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31100 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31200 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31300 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31400 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31500 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31600 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31700 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31800 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 31900 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32000 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32100 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32200 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32300 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32400 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32500 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32600 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32700 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32800 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 32900 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33000 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33100 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33200 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33300 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33400 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33500 loss: 0.0057 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33600 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33700 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33800 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 33900 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34000 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 34100 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34200 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34300 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34400 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34500 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34600 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34700 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34800 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 34900 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35000 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35100 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35200 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35300 loss: 0.0060 scmap loss: 0.0058 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35400 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35500 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35600 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35700 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35800 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 35900 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36000 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36100 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36200 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36300 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36400 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36500 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36600 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36700 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36800 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 36900 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37000 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37100 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37200 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37300 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37400 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37500 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37600 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37700 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37800 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 37900 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38000 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38100 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38200 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38300 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38400 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38500 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38600 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38700 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38800 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 38900 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39000 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39100 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39200 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39300 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39400 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39500 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39600 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39700 loss: 0.0056 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39800 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 39900 loss: 0.0058 scmap loss: 0.0056 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40000 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40100 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40200 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40300 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40400 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40500 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40600 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40700 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40800 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 40900 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41000 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41100 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41200 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41300 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41400 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41500 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41600 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41700 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41800 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 41900 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42000 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42100 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42200 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42300 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42400 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42500 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 42600 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42700 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42800 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 42900 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43000 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43100 loss: 0.0047 scmap loss: 0.0045 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43200 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43300 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43400 loss: 0.0057 scmap loss: 0.0055 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43500 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43600 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43700 loss: 0.0055 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43800 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 43900 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44000 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44100 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44200 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44300 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44400 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44500 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44600 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44700 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44800 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 44900 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45000 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45100 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45200 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45300 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45400 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45500 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45600 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45700 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45800 loss: 0.0053 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 45900 loss: 0.0055 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46000 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46100 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46200 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46300 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46400 loss: 0.0056 scmap loss: 0.0054 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46500 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46600 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46700 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46800 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 46900 loss: 0.0049 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47000 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47100 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47200 loss: 0.0047 scmap loss: 0.0045 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47300 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47400 loss: 0.0048 scmap loss: 0.0046 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47500 loss: 0.0046 scmap loss: 0.0045 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47600 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47700 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47800 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 47900 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48000 loss: 0.0047 scmap loss: 0.0046 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48100 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48200 loss: 0.0053 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48300 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48400 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48500 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48600 loss: 0.0047 scmap loss: 0.0046 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48700 loss: 0.0049 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48800 loss: 0.0051 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 48900 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49000 loss: 0.0054 scmap loss: 0.0052 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49100 loss: 0.0052 scmap loss: 0.0051 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49200 loss: 0.0046 scmap loss: 0.0045 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49300 loss: 0.0048 scmap loss: 0.0047 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49400 loss: 0.0046 scmap loss: 0.0045 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49500 loss: 0.0050 scmap loss: 0.0049 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49600 loss: 0.0050 scmap loss: 0.0048 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49700 loss: 0.0047 scmap loss: 0.0046 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49800 loss: 0.0052 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 49900 loss: 0.0054 scmap loss: 0.0053 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "iteration: 50000 loss: 0.0051 scmap loss: 0.0050 locref loss: 0.0001 limb loss: 0.0001 lr: 1e-05\n",
      "Exception in thread Thread-6 (load_and_enqueue):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vsridhar/.local/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 85, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"/home/vsridhar/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/vsridhar/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1115, in _run\n",
      "    raise RuntimeError('Attempted to use a closed Session.')\n",
      "RuntimeError: Attempted to use a closed Session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path,\n",
    "                         gputouse=0, \n",
    "                         displayiters=100,\n",
    "                         saveiters=10000,\n",
    "                         maxiters=50000,\n",
    "                         allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fbd5364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['centre', 'left', 'right'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_06_TerritoryDetectionP1Aug1/06_TerritoryDetectionP1_Vivek90shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/vsridhar/.local/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_smooth': False,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'minconfidence': 0.01,\n",
      " 'mirror': False,\n",
      " 'multi_stage': True,\n",
      " 'net_type': 'resnet_50',\n",
      " 'nmsradius': 5.0,\n",
      " 'num_idchannel': 0,\n",
      " 'num_joints': 3,\n",
      " 'num_limbs': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'sigma': 1,\n",
      " 'snapshot_prefix': '/media/vsridhar/DATA/DeepLabCut/projects/06_TerritoryDetectionP1-Vivek-2023-08-01/dlc-models/iteration-0/06_TerritoryDetectionP1Aug1-trainset90shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/vsridhar/.local/lib/python3.10/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_dlcrnetms5_06_TerritoryDetectionP1Aug1shuffle1_50000  with # of trainingiterations: 50000\n",
      "Activating extracting of PAFs\n",
      "Network Evaluation underway...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:05, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 50000 training iterations, training fraction of 90, and shuffle 1:\n",
      "Train error: 2.9 pixels. Test error: 3.13 pixels.\n",
      "With pcutoff of 0.6:\n",
      "Train error: 2.85 pixels. Test error: 3.09 pixels.\n",
      "##########################################\n",
      "Average Euclidean distance to GT per individual (in pixels; test-only)\n",
      "individuals\n",
      "territory1     3.256052\n",
      "territory10    2.549636\n",
      "territory11    3.219142\n",
      "territory12    3.172717\n",
      "territory13    2.850549\n",
      "territory14    2.743324\n",
      "territory15    3.000371\n",
      "territory16    2.341627\n",
      "territory17    2.837494\n",
      "territory18    2.687152\n",
      "territory19    3.051094\n",
      "territory2     3.248105\n",
      "territory20    2.918743\n",
      "territory21    3.639393\n",
      "territory22    2.974232\n",
      "territory23    5.130773\n",
      "territory24    5.850537\n",
      "territory25    2.914917\n",
      "territory26    3.897852\n",
      "territory27    2.961033\n",
      "territory28    2.382644\n",
      "territory29    2.443534\n",
      "territory3     2.843358\n",
      "territory30    2.689383\n",
      "territory31    2.614329\n",
      "territory32    3.795226\n",
      "territory33    1.757495\n",
      "territory34    2.924377\n",
      "territory35    3.233694\n",
      "territory36    2.753619\n",
      "territory37    3.403234\n",
      "territory38    2.469948\n",
      "territory39    2.206351\n",
      "territory4     3.252299\n",
      "territory40    1.426585\n",
      "territory41    3.066357\n",
      "territory42    2.034873\n",
      "territory43         NaN\n",
      "territory44         NaN\n",
      "territory45         NaN\n",
      "territory46         NaN\n",
      "territory47         NaN\n",
      "territory48         NaN\n",
      "territory49         NaN\n",
      "territory5     2.670556\n",
      "territory50         NaN\n",
      "territory51         NaN\n",
      "territory52         NaN\n",
      "territory53         NaN\n",
      "territory54         NaN\n",
      "territory55         NaN\n",
      "territory56         NaN\n",
      "territory57         NaN\n",
      "territory58         NaN\n",
      "territory59         NaN\n",
      "territory6     2.754435\n",
      "territory60         NaN\n",
      "territory7     3.451077\n",
      "territory8     3.078680\n",
      "territory9     3.599482\n",
      "Average Euclidean distance to GT per bodypart (in pixels; test-only)\n",
      "bodyparts\n",
      "centre    2.575011\n",
      "left      3.200755\n",
      "right     3.597182\n",
      "Done and results stored for snapshot:  snapshot-50000\n",
      "Selecting best skeleton...\n",
      "Graph 1|2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 336.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:05<00:00, 10.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 1065.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 2|2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 106.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:05<00:00, 10.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 1059.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:36<00:00,  1.65it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1824x1026 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path,\n",
    "                            plotting='individual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d6896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
